{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Making and Counting ngrams in python\n",
    "date: 2024-02-13\n",
    "categories:\n",
    "    - python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll work through some of the practicalities of creating and counting ngrams from text. Let's grab the book first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"book-getting function\"\n",
    "from gutenbergpy.textget \\\n",
    "    import get_text_by_id,\\\n",
    "           strip_headers\n",
    "\n",
    "def get_clean_book(book_id):\n",
    "    \"\"\"Get the cleaned book\n",
    "\n",
    "    Args:\n",
    "        book_id (str|int): The book id\n",
    "\n",
    "    Returns:\n",
    "        (str): The full book\n",
    "    \"\"\"\n",
    "    raw_book = get_text_by_id(book_id)\n",
    "    book_byte = strip_headers(raw_book)\n",
    "    book_clean = book_byte.decode(\"utf-8\")\n",
    "\n",
    "    return book_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick = get_clean_book(2701)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, unigrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step will be getting the \"unigram\" frequencies.\n",
    "\n",
    "| words in context | words to predict | total | name |\n",
    "| ---------------: | ---------------: | ----: | :--- |\n",
    "| 0                | 1                | 1     | unigram |\n",
    "| 1                | 1                | 2     | bigram |\n",
    "| 2                | 2                | 3     | trigram |\n",
    "\n",
    "To get *any* counts, we need to tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "moby_words = word_tokenize(moby_dick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can count with `collections.Counter()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19211),\n",
       " ('the', 13717),\n",
       " ('.', 7164),\n",
       " ('of', 6563),\n",
       " ('and', 6009),\n",
       " ('to', 4515),\n",
       " ('a', 4507),\n",
       " (';', 4178),\n",
       " ('in', 3915),\n",
       " ('that', 2918)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "moby_count = Counter(moby_words)\n",
    "moby_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *\"unigram\"* probability of a word:\n",
    "$$\n",
    "P(w_i) = \\frac{C(w_i)}{\\sum_{i=1}^n C(w_i)}\n",
    "$$\n",
    "\n",
    "We can get $C(w_i)$ from the counter dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_count[\"whale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trickier thing to get is $\\sum_{i=1}^n C(w_i)$. One way to do it is with a for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255958"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_freq = 0\n",
    "for word in moby_count:\n",
    "    total_freq += moby_count[word]\n",
    "\n",
    "total_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `total_freq`, we can calculate the probability of each token, which we can store in another dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030122129411856635"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_prob = {}\n",
    "for word in moby_count:\n",
    "    moby_prob[word] = moby_count[word] / total_freq\n",
    "\n",
    "moby_prob[\"whale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing numpy\n",
    "\n",
    "`numpy` is a python package that allows you to do numeric computation more easilly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you need to install it:\n",
    "# ! pip install numpy\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just had a python list of numbers, we couldn't quickly divide each number by the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43msample_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "sample_list = [0, 1, 3]\n",
    "sample_list / sum(sample_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We *can* do this with a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.25, 0.75])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_array = np.array([0, 1, 3])\n",
    "sample_array / sample_array.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's lots of numpy methods to make life easier when working with numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    sample_array.min(), \n",
    "    sample_array.max()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating tokens, counts and probabilities\n",
    "\n",
    "While the dictionary `moby_count` is convenient for quickly getting the count of a token, we'll need separate lists and arrays for:\n",
    "\n",
    "- the text of each token\n",
    "- the count of each token\n",
    "- the probability of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of the text of each token\n",
    "word_list = [w for w in moby_count]\n",
    "\n",
    "# an array of the count of each token\n",
    "count_array = np.array(\n",
    "    [\n",
    "        moby_count[w] \n",
    "        for w in word_list\n",
    "    ]\n",
    ")\n",
    "\n",
    "# a array of the probability of each token\n",
    "prob_array = count_array / count_array.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A thing to think about is how the mathematical formula on the left is being *implemented* in the code on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{layout-ncol=2}\n",
    "\n",
    "::::{.column}\n",
    "\n",
    "$$\n",
    "\\frac{C(w_i)}{\\sum_{i=1}^n w_i}\n",
    "$$\n",
    "\n",
    "::::\n",
    "\n",
    "::::{.column}\n",
    "\n",
    "```python\n",
    "count_array / count_array.sum()\n",
    "```\n",
    "\n",
    "::::\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a specific word's probability like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030122129411856635"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_array[\n",
    "    word_list.index(\"whale\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Sampling\" random words\n",
    "\n",
    "We can sample a random word from the unigram distribution like so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['it', 'letter', 'compasses', 'and', 'cut', 'lot', 'a', 'thus',\n",
       "       'flew', 'With'], dtype='<U28')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(\n",
    "    word_list, \n",
    "    size = 10, \n",
    "    p = prob_array\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Bigrams\n",
    "\n",
    "Making bigrams is a bit more complex. We need to get counts of each sequence of two tokens. Fortunately, `nltk` has a nice and convenient function for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Call', 'me'), ('me', 'Ishmael'), ('Ishmael', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "sent1 = [\"Call\", \"me\", \"Ishmael\", \".\"]\n",
    "\n",
    "list(\n",
    "    ngrams(sent1, n = 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of \"tuples\". Tuples are kind of like lists, but you're not able to edit them after you create them. We can use  `Counter()` on a list of tuples just like we did a list of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'and'), 2630),\n",
       " (('of', 'the'), 1869),\n",
       " (('’', 's'), 1784),\n",
       " (('in', 'the'), 1122),\n",
       " ((',', 'the'), 916),\n",
       " ((';', 'and'), 857),\n",
       " (('to', 'the'), 715),\n",
       " (('.', 'But'), 596),\n",
       " (('.', '“'), 594),\n",
       " ((',', 'that'), 583)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_bigram_count = Counter(\n",
    "    ngrams(moby_words, 2)\n",
    ")\n",
    "\n",
    "moby_bigram_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list = [bigram for bigram in moby_bigram_count]\n",
    "bigram_count = np.array(\n",
    "    [moby_bigram_count[bigram] for bigram in bigram_list]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting *conditional* probabilities\n",
    "\n",
    "Now, getting the probability of a single token isn't as straightforward, since we're looking at *conditional* probabilities.\n",
    "\n",
    "$$\n",
    "P(w_i | w_{i-1}) = \\frac{C(w_{i-1}w_i)}{\\sum C(w_{i-1}w)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use concrete words for a second:\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\text{whale} | \\text{the}) = \\frac{C(\\text{the whale})}{\\sum C(\\text{the }w)}\n",
    "$$\n",
    "\n",
    "So, to calculate the conditional probability, we need to get\n",
    "\n",
    "- The count of the bigram \"the whale\"\n",
    "- A list (or array) of the count of *every* bigram that begins with \"the\".\n",
    "- The sum of this second list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'Whale'),\n",
       " ('the', 'Monstrous'),\n",
       " ('the', 'Less'),\n",
       " ('the', 'True'),\n",
       " ('the', 'Hand'),\n",
       " ('the', 'Arsacides'),\n",
       " ('the', 'Carpenter'),\n",
       " ('the', 'Cabin'),\n",
       " ('the', 'End'),\n",
       " ('the', 'First')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first word in the\n",
    "# 2 word sequence\n",
    "w_0 = \"the\"\n",
    "\n",
    "w_0w = [\n",
    "    bigram \n",
    "    for bigram in moby_bigram_count\n",
    "    if bigram[0] == w_0\n",
    "]\n",
    "\n",
    "w_0w[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13717"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_w_0w = np.array(\n",
    "    [\n",
    "        moby_bigram_count[bigram]\n",
    "        for bigram in w_0w\n",
    "    ]\n",
    ")\n",
    "\n",
    "total_w_0 = C_w_0w.sum()\n",
    "\n",
    "total_w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the specific conditional probability for the word \"whale\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_bigram_count[\n",
    "    (\"the\", \"whale\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02369322738208063"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_bigram_count[\n",
    "    (\"the\", \"whale\")\n",
    "] / total_w_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To randomly generate *any* word following \"the\", we need to get the probability distribution across bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hammers', 'steak', 'chances', 'house'], dtype='<U21')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_w_0w = C_w_0w / C_w_0w.sum()\n",
    "\n",
    "w_1 = [bigram[1] for bigram in w_0w]\n",
    "\n",
    "np.random.choice(\n",
    "    w_1,\n",
    "    size = 4,\n",
    "    p = P_w_0w\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a *sequence*, starting with a specific word, we need to encapsulate our logic above into a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(\n",
    "        bigram_count:dict,\n",
    "        w_0:str = \"The\", \n",
    "        n:int = 10\n",
    "        )->list[str]:\n",
    "    \"\"\"Generate a sequence of words from \n",
    "    a bigram model\n",
    "\n",
    "    Args:\n",
    "        w_0 (str): The initial token\n",
    "        n (int): The size of the sequence\n",
    "            to generate\n",
    "\n",
    "    Returns:\n",
    "        (list[str]): The generated sequence\n",
    "    \"\"\"\n",
    "    ## start out with the seed token\n",
    "    sequence = [w_0]\n",
    "\n",
    "    for i in range(n):\n",
    "        ## The new seed token should be\n",
    "        ## the last one added\n",
    "        w_0 = sequence[-1]\n",
    "\n",
    "        ## get all bigrams beginning \n",
    "        ## with the seed token\n",
    "        w_0w = [\n",
    "            bigram \n",
    "            for bigram in bigram_count\n",
    "            if bigram[0] == w_0\n",
    "        ]\n",
    "\n",
    "        ## get the counts of all bigrams\n",
    "        C_w_0w = np.array([\n",
    "            bigram_count[bigram]\n",
    "            for bigram in w_0w\n",
    "        ])\n",
    "\n",
    "        ## get the probabilities of all bigrams\n",
    "        P_w_0w = C_w_0w / C_w_0w.sum()\n",
    "\n",
    "        ## get the second token \n",
    "        ## from every bigram\n",
    "        w_1 = [\n",
    "            bigram[1]\n",
    "            for bigram in w_0w\n",
    "        ]\n",
    "\n",
    "        ## sample a new token\n",
    "        chosen = np.random.choice(\n",
    "            w_1,\n",
    "            size = 1,\n",
    "            p = P_w_0w\n",
    "        )\n",
    "\n",
    "        ## add the sampled token to the \n",
    "        ## sequence\n",
    "        sequence.append(chosen[0])\n",
    "\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'heavers',\n",
       " 'singing',\n",
       " 'in',\n",
       " 'his',\n",
       " 'suit',\n",
       " ',',\n",
       " 'filled',\n",
       " 'for',\n",
       " 'their',\n",
       " 'spirits']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence(moby_bigram_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "\n",
    "The bigram sequence generator above has to start out on a specific word, and it will keep going for as many loops as we tell it. \n",
    "\n",
    "If we wanted a generator that doesn't need a specific word to start on, and will auto-stop when it gets to the end of a sentence, we'll need to pre-process our data differently, so that there are special \"start\" and \"stop\" symbols, or \"padding\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep into distant woodlands\n",
      "winds a mazy way, reaching to overlapping spurs of mountains bathed in\n",
      "their hill-side blue.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "moby_sentences = sent_tokenize(moby_dick)\n",
    "\n",
    "print(moby_sentences[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep',\n",
       " 'into',\n",
       " 'distant',\n",
       " 'woodlands',\n",
       " 'winds',\n",
       " 'a',\n",
       " 'mazy',\n",
       " 'way',\n",
       " ',',\n",
       " 'reaching',\n",
       " 'to',\n",
       " 'overlapping',\n",
       " 'spurs',\n",
       " 'of',\n",
       " 'mountains',\n",
       " 'bathed',\n",
       " 'in',\n",
       " 'their',\n",
       " 'hill-side',\n",
       " 'blue',\n",
       " '.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_sent_words = [\n",
    "    word_tokenize(sentence) \n",
    "    for sentence in moby_sentences\n",
    "]\n",
    "\n",
    "moby_sent_words[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'Deep',\n",
       " 'into',\n",
       " 'distant',\n",
       " 'woodlands',\n",
       " 'winds',\n",
       " 'a',\n",
       " 'mazy',\n",
       " 'way',\n",
       " ',',\n",
       " 'reaching',\n",
       " 'to',\n",
       " 'overlapping',\n",
       " 'spurs',\n",
       " 'of',\n",
       " 'mountains',\n",
       " 'bathed',\n",
       " 'in',\n",
       " 'their',\n",
       " 'hill-side',\n",
       " 'blue',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_sent_words_padded = [\n",
    "    [\"<s>\"] + sent + [\"</s>\"]\n",
    "    for sent in moby_sent_words\n",
    "]\n",
    "\n",
    "moby_sent_words_padded[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_words2 = [\n",
    "    token \n",
    "    for sent in moby_sent_words_padded\n",
    "        for token in sent\n",
    "]\n",
    "\n",
    "moby_bigrams2 = ngrams(moby_words2, n = 2)\n",
    "moby_bigram_count2 = Counter(moby_bigrams2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'With',\n",
       " 'what',\n",
       " 'business',\n",
       " ',',\n",
       " 'Starbuck',\n",
       " 'caught',\n",
       " 'one',\n",
       " 'foot',\n",
       " 'part—what',\n",
       " 'a',\n",
       " 'chess-man',\n",
       " 'beside',\n",
       " 'the',\n",
       " 'rolling',\n",
       " 'on',\n",
       " 'the',\n",
       " 'boats',\n",
       " 'and',\n",
       " 'sunk',\n",
       " '!']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sequence(\n",
    "    moby_bigram_count2, \n",
    "    w_0 = \"<s>\", \n",
    "    n = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing it faster with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "ngram_size = 3\n",
    "\n",
    "train, vocab = padded_everygram_pipeline(ngram_size, moby_sent_words)\n",
    "lm = MLE(ngram_size)\n",
    "lm.fit(train, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::codebox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'had',\n",
       " 'turned',\n",
       " ',',\n",
       " 'and',\n",
       " 'continually',\n",
       " 'set',\n",
       " 'in',\n",
       " 'a',\n",
       " 'calm—give',\n",
       " 'us',\n",
       " 'a',\n",
       " 'blue',\n",
       " 'hanging',\n",
       " 'tester',\n",
       " 'of',\n",
       " 'smoke',\n",
       " ',',\n",
       " 'illuminated',\n",
       " 'by',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'my',\n",
       " 'own',\n",
       " 'voice',\n",
       " '.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [\"<s>\", \"<s>\"]\n",
    "for i in range(100):\n",
    "    w_0 = sequence[-2:]\n",
    "    new = lm.generate(num_words=1, text_seed=w_0)\n",
    "    sequence.append(new)\n",
    "    if new == \"</s>\":\n",
    "        break\n",
    "\n",
    "sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "renv-python-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
