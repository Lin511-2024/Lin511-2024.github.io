{
  "hash": "eeae8db1d3d04198c261d7453d6c43cf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"ngrams\"\nsubtitle: \"-or- What if we *could* parse natural language with a finite state automaton?\"\ndate: 2024-02-05\nfilters: \n  - codeblocklabel\n---\n\n\nSo, in our notes on [finite state automata](01_fsm.qmd) and [push-down automata](02_pda.qmd) that since natural language has bracket matching patterns, and maybe even crossing dependencies, that it's more complex than a \"regular\" language, and can't really be parsed with a finite state automaton.\n\nngram language modelling asks the question: But what if we tried really hard?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\na=1\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npy$a\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}